# TrendRadar API ä½¿ç”¨æŒ‡å—

TrendRadar API æä¾›åŸºäºå¤§æ¨¡å‹çš„çƒ­ç‚¹æ–°é—»æ™ºèƒ½åˆ†æåŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®å¤§æ¨¡å‹ API

åœ¨ `config/config.yaml` ä¸­é…ç½®å¤§æ¨¡å‹å‚æ•°,æˆ–é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼ˆæ¨èï¼‰:

```bash
# OpenAI
export LLM_API_KEY="sk-..."
export LLM_BASE_URL="https://api.openai.com/v1"
export LLM_MODEL="gpt-4"

# DeepSeek
export LLM_API_KEY="sk-..."
export LLM_BASE_URL="https://api.deepseek.com/v1"
export LLM_MODEL="deepseek-chat"

# Moonshot
export LLM_API_KEY="sk-..."
export LLM_BASE_URL="https://api.moonshot.cn/v1"
export LLM_MODEL="moonshot-v1-8k"

# æœ¬åœ° Ollama
export LLM_BASE_URL="http://localhost:11434/v1"
export LLM_MODEL="llama3"
export LLM_API_KEY="not-required"  # æœ¬åœ°æ¨¡å‹ä¸éœ€è¦ API Key
```

### 3. å¯åŠ¨æœåŠ¡å™¨

```bash
# æ–¹å¼ä¸€: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
./start-api.sh

# æ–¹å¼äºŒ: ç›´æ¥ä½¿ç”¨ uvicorn
uvicorn src.api.server:app --host 0.0.0.0 --port 8000 --reload

# æ–¹å¼ä¸‰: è¿è¡Œ Python æ¨¡å—
python -m uvicorn src.api.server:app --host 0.0.0.0 --port 8000
```

æœåŠ¡å™¨å¯åŠ¨åè®¿é—®:
- **API æ–‡æ¡£**: http://localhost:8000/docs (Swagger UI)
- **ReDoc æ–‡æ¡£**: http://localhost:8000/redoc
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health

---

## ğŸ“¡ API æ¥å£è¯´æ˜

### ç³»ç»Ÿç›¸å…³

#### 1. è·å–ç³»ç»ŸçŠ¶æ€

```bash
GET /api/v1/system/status
```

è¿”å›æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€ã€æ´»è·ƒä¼šè¯æ•°ç­‰ä¿¡æ¯ã€‚

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "service": "TrendRadar API",
    "version": "1.0.0",
    "status": "running",
    "uptime": "2å°æ—¶30åˆ†é’Ÿ",
    "llm_configured": true,
    "storage_path": "conversations",
    "active_sessions": 5
  }
}
```

#### 2. è·å–é…ç½®ä¿¡æ¯

```bash
GET /api/v1/system/config
```

è¿”å›å½“å‰çš„ç³»ç»Ÿé…ç½®ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰ã€‚

#### 3. è·å–æœ€æ–°æ–°é—»

```bash
GET /api/v1/news/latest?platforms=zhihu,weibo&limit=50
```

**å‚æ•°**:
- `platforms`: å¹³å°ç­›é€‰,å¤šä¸ªç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰
- `limit`: è¿”å›æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤ 50ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "total": 50,
    "date": "2025å¹´11æœˆ12æ—¥",
    "news": [
      {
        "title": "æ–°é—»æ ‡é¢˜",
        "platform": "çŸ¥ä¹",
        "rank": 1,
        "count": 3,
        "weight": 85.6
      }
    ]
  }
}
```

### å¯¹è¯ç›¸å…³

#### 4. åˆ›å»ºä¼šè¯

```bash
POST /api/v1/chat/sessions
Content-Type: application/json

{
  "inject_context": true,
  "platforms": ["zhihu", "weibo"],
  "news_limit": 50
}
```

**å‚æ•°è¯´æ˜**:
- `inject_context`: æ˜¯å¦è‡ªåŠ¨æ³¨å…¥æœ€æ–°æ–°é—»æ•°æ®ï¼ˆé¦–è½®å»ºè®® trueï¼‰
- `platforms`: å¹³å°ç­›é€‰ï¼ˆå¯é€‰ï¼‰
- `news_limit`: æ³¨å…¥çš„æ–°é—»æ•°é‡ï¼ˆé»˜è®¤ 50ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "session_id": "uuid-xxx",
    "created_at": "2025-11-12T16:32:00",
    "context_injected": true,
    "news_count": 50
  },
  "message": "ä¼šè¯åˆ›å»ºæˆåŠŸ"
}
```

#### 5. å‘é€æ¶ˆæ¯

```bash
POST /api/v1/chat/sessions/{session_id}/messages
Content-Type: application/json

{
  "message": "åˆ†æä»Šå¤©çŸ¥ä¹å’Œå¾®åšçš„çƒ­ç‚¹,æœ‰ä»€ä¹ˆå…±åŒè¯é¢˜?",
  "inject_context": false
}
```

**å‚æ•°è¯´æ˜**:
- `message`: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¿…å¡«ï¼‰
- `inject_context`: æ˜¯å¦é‡æ–°æ³¨å…¥æœ€æ–°æ•°æ®ï¼ˆå¯é€‰,ç”¨äºæ›´æ–°ä¸Šä¸‹æ–‡ï¼‰
- `platforms`: å¹³å°ç­›é€‰ï¼ˆå¯é€‰ï¼‰

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "reply": "æ ¹æ®æ•°æ®åˆ†æ,ä»Šå¤©çŸ¥ä¹å’Œå¾®åšçš„å…±åŒçƒ­ç‚¹æœ‰...",
    "session_id": "uuid-xxx",
    "timestamp": "2025-11-12T16:35:00",
    "token_usage": {
      "prompt_tokens": 1500,
      "completion_tokens": 300,
      "total_tokens": 1800
    }
  },
  "message": "æ¶ˆæ¯å‘é€æˆåŠŸ"
}
```

#### 6. è·å–ä¼šè¯å†å²

```bash
GET /api/v1/chat/sessions/{session_id}
```

è¿”å›å®Œæ•´çš„ä¼šè¯ä¿¡æ¯å’Œæ¶ˆæ¯å†å²ã€‚

#### 7. åˆ é™¤ä¼šè¯

```bash
DELETE /api/v1/chat/sessions/{session_id}
```

æ°¸ä¹…åˆ é™¤æŒ‡å®šä¼šè¯ã€‚

#### 8. åˆ—å‡ºæ‰€æœ‰ä¼šè¯

```bash
GET /api/v1/chat/sessions?limit=100
```

è¿”å›æ‰€æœ‰ä¼šè¯ ID åˆ—è¡¨ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´å€’åºï¼‰ã€‚

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### Python å®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests

BASE_URL = "http://localhost:8000/api/v1"

# 1. åˆ›å»ºä¼šè¯
resp = requests.post(f"{BASE_URL}/chat/sessions", json={
    "inject_context": True,
    "platforms": ["zhihu", "weibo"],
    "news_limit": 50
})
session_id = resp.json()["data"]["session_id"]
print(f"ä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")

# 2. å‘é€æ¶ˆæ¯
resp = requests.post(
    f"{BASE_URL}/chat/sessions/{session_id}/messages",
    json={
        "message": "æ€»ç»“ä»Šå¤©æœ€çƒ­é—¨çš„ 5 æ¡æ–°é—»,å¹¶åˆ†æè¶‹åŠ¿"
    }
)
reply = resp.json()["data"]["reply"]
print(f"AI å›å¤: {reply}")

# 3. ç»§ç»­å¯¹è¯
resp = requests.post(
    f"{BASE_URL}/chat/sessions/{session_id}/messages",
    json={
        "message": "è¿™äº›æ–°é—»ä¸­æœ‰å“ªäº›æ˜¯ç§‘æŠ€ç›¸å…³çš„?"
    }
)
print(f"AI å›å¤: {resp.json()['data']['reply']}")

# 4. è·å–ä¼šè¯å†å²
resp = requests.get(f"{BASE_URL}/chat/sessions/{session_id}")
messages = resp.json()["data"]["messages"]
print(f"å…± {len(messages)} æ¡æ¶ˆæ¯")
```

### JavaScript/å‰ç«¯ç¤ºä¾‹

```javascript
const BASE_URL = 'http://localhost:8000/api/v1';

async function startChat() {
    // 1. åˆ›å»ºä¼šè¯
    const session = await fetch(`${BASE_URL}/chat/sessions`, {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            inject_context: true,
            platforms: ['zhihu'],
            news_limit: 30
        })
    }).then(r => r.json());

    const sessionId = session.data.session_id;
    console.log('ä¼šè¯åˆ›å»ºæˆåŠŸ:', sessionId);

    // 2. å‘é€æ¶ˆæ¯
    const response = await fetch(
        `${BASE_URL}/chat/sessions/${sessionId}/messages`,
        {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                message: 'åˆ†æä»Šå¤©çŸ¥ä¹çš„çƒ­ç‚¹è¯é¢˜'
            })
        }
    ).then(r => r.json());

    console.log('AI å›å¤:', response.data.reply);
    console.log('Token ä½¿ç”¨:', response.data.token_usage);
}

startChat();
```

### curl ç¤ºä¾‹

```bash
# 1. åˆ›å»ºä¼šè¯
SESSION_ID=$(curl -s -X POST http://localhost:8000/api/v1/chat/sessions \
  -H "Content-Type: application/json" \
  -d '{"inject_context": true}' \
  | jq -r '.data.session_id')

echo "ä¼šè¯ ID: $SESSION_ID"

# 2. å‘é€æ¶ˆæ¯
curl -X POST http://localhost:8000/api/v1/chat/sessions/$SESSION_ID/messages \
  -H "Content-Type: application/json" \
  -d '{"message": "æ€»ç»“ä»Šå¤©çš„çƒ­ç‚¹æ–°é—»"}' \
  | jq '.data.reply'

# 3. è·å–ä¼šè¯å†å²
curl http://localhost:8000/api/v1/chat/sessions/$SESSION_ID | jq
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### å¤§æ¨¡å‹é…ç½® (config.yaml)

```yaml
llm:
  provider: "openai"  # æœåŠ¡å•†æ ‡è¯†
  base_url: "https://api.openai.com/v1"  # API åŸºç¡€ URL
  api_key: ""  # å»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
  model: "gpt-4"  # æ¨¡å‹åç§°
  max_tokens: 2000  # æœ€å¤§ç”Ÿæˆ Token æ•°
  temperature: 0.7  # æ¸©åº¦å‚æ•°ï¼ˆ0-2ï¼‰
  timeout: 60  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
```

### å¯¹è¯é…ç½® (config.yaml)

```yaml
chat:
  storage_path: "conversations"  # ä¼šè¯å­˜å‚¨ç›®å½•
  max_history_length: 20  # å•ä¸ªä¼šè¯ä¿ç•™çš„æœ€å¤§å†å²æ¶ˆæ¯æ•°
  context_news_limit: 50  # é¦–è½®å¯¹è¯æ³¨å…¥çš„æœ€å¤§æ–°é—»æ•°é‡
  enable_streaming: false  # æµå¼è¾“å‡ºï¼ˆæœªæ¥åŠŸèƒ½ï¼‰
```

### ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§

ç¯å¢ƒå˜é‡ä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®:

```bash
export LLM_API_KEY="your-api-key"
export LLM_BASE_URL="https://api.example.com/v1"
export LLM_MODEL="gpt-4"
export LLM_MAX_TOKENS="2000"
export LLM_TEMPERATURE="0.7"
export LLM_TIMEOUT="60"
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. API Key æœªé…ç½®

**é”™è¯¯**: `è­¦å‘Š: æœªé…ç½® API Key`

**è§£å†³æ–¹æ³•**:
```bash
export LLM_API_KEY="your-api-key"
./start-api.sh
```

### 2. ç«¯å£è¢«å ç”¨

**é”™è¯¯**: `Address already in use`

**è§£å†³æ–¹æ³•**:
```bash
# æŸ¥æ‰¾å ç”¨ 8000 ç«¯å£çš„è¿›ç¨‹
lsof -i:8000

# æ€æ­»è¿›ç¨‹æˆ–æ›´æ¢ç«¯å£
uvicorn src.api.server:app --port 8001
```

### 3. æœªæ‰¾åˆ°æ–°é—»æ•°æ®

**é”™è¯¯**: `æœªæ‰¾åˆ° 2025å¹´11æœˆ12æ—¥ çš„æ–°é—»æ•°æ®`

**åŸå› **: ä»Šå¤©è¿˜æ²¡æœ‰è¿è¡Œçˆ¬è™«æˆ–æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ã€‚

**è§£å†³æ–¹æ³•**:
```bash
# å…ˆè¿è¡Œçˆ¬è™«ç”Ÿæˆæ•°æ®
python main.py

# ç„¶åå¯åŠ¨ API æœåŠ¡å™¨
./start-api.sh
```

### 4. Token ä½¿ç”¨é‡è¿‡å¤§

**é—®é¢˜**: æ¯æ¬¡è¯·æ±‚æ¶ˆè€—å¤§é‡ Token

**ä¼˜åŒ–å»ºè®®**:
- å‡å°‘ `news_limit` å‚æ•°ï¼ˆé»˜è®¤ 50 â†’ 20-30ï¼‰
- å‡å°‘ `max_history_length`ï¼ˆé»˜è®¤ 20 â†’ 10ï¼‰
- é¦–è½®å¯¹è¯åå°† `inject_context` è®¾ä¸º `false`

---

## ğŸ“Š æ•°æ®æ ¼å¼è¯´æ˜

### ç²¾ç®€çš„æ–°é—»æ•°æ®æ ¼å¼

ä¸ºäº†èŠ‚çœ Token,é¦–è½®å¯¹è¯æ³¨å…¥çš„æ–°é—»æ•°æ®ä»…åŒ…å«æ ¸å¿ƒå­—æ®µ:

```json
{
  "title": "æ–°é—»æ ‡é¢˜",
  "platform": "çŸ¥ä¹",
  "rank": 1,
  "count": 3,
  "weight": 85.6
}
```

**å­—æ®µè¯´æ˜**:
- `title`: æ–°é—»æ ‡é¢˜
- `platform`: æ¥æºå¹³å°
- `rank`: åœ¨å¹³å°çš„æ’åï¼ˆè¶Šå°è¶Šçƒ­é—¨ï¼‰
- `count`: åœ¨ä¸åŒæ‰¹æ¬¡ä¸­å‡ºç°çš„æ¬¡æ•°ï¼ˆæŒç»­çƒ­åº¦ï¼‰
- `weight`: ç»¼åˆæƒé‡åˆ†æ•°ï¼ˆ0-100,è¶Šé«˜è¶Šé‡è¦ï¼‰

**ä¼˜åŒ–æ•ˆæœ**: ç›¸æ¯”å®Œæ•´æ•°æ®èŠ‚çœçº¦ 60% Token

---

## ğŸš¢ ç”Ÿäº§éƒ¨ç½²

### Docker éƒ¨ç½²

åˆ›å»º `Dockerfile`:

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "src.api.server:app", "--host", "0.0.0.0", "--port", "8000"]
```

æ„å»ºå¹¶è¿è¡Œ:

```bash
docker build -t trendradar-api .

docker run -d \
  --name trendradar-api \
  -p 8000:8000 \
  -e LLM_API_KEY="your-api-key" \
  -e LLM_BASE_URL="https://api.openai.com/v1" \
  -e LLM_MODEL="gpt-4" \
  -v $(pwd)/conversations:/app/conversations \
  -v $(pwd)/output:/app/output:ro \
  trendradar-api
```

### Nginx åå‘ä»£ç†

```nginx
server {
    listen 80;
    server_name api.example.com;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **API åœ¨çº¿æ–‡æ¡£**: http://localhost:8000/docs
- **é¡¹ç›®ä¸»æ–‡æ¡£**: [README.md](../README.md)
- **æ¶æ„è®¾è®¡**: [REFACTORING_SUMMARY.md](../REFACTORING_SUMMARY.md)
- **MCP æœåŠ¡å™¨**: [README-MCP-FAQ.md](../README-MCP-FAQ.md)

---

## ğŸ’¬ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜,è¯·æäº¤ Issue: https://github.com/sansan0/TrendRadar/issues
